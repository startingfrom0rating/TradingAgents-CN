"""
æ–°é—»æ•°æ®æœåŠ¡
æä¾›ç»Ÿä¸€çš„æ–°é—»æ•°æ®å­˜å‚¨ã€æŸ¥è¯¢å’Œç®¡ç†åŠŸèƒ½
"""
from typing import Optional, List, Dict, Any, Union
from datetime import datetime, timedelta
from dataclasses import dataclass
import logging
from pymongo import ReplaceOne
from pymongo.errors import BulkWriteError

from app.core.database import get_database

logger = logging.getLogger(__name__)


@dataclass
class NewsQueryParams:
    """æ–°é—»æŸ¥è¯¢å‚æ•°"""
    symbol: Optional[str] = None
    symbols: Optional[List[str]] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    category: Optional[str] = None
    sentiment: Optional[str] = None
    importance: Optional[str] = None
    data_source: Optional[str] = None
    keywords: Optional[List[str]] = None
    limit: int = 50
    skip: int = 0
    sort_by: str = "publish_time"
    sort_order: int = -1  # -1 for desc, 1 for asc


@dataclass
class NewsStats:
    """æ–°é—»ç»Ÿè®¡ä¿¡æ¯"""
    total_count: int = 0
    positive_count: int = 0
    negative_count: int = 0
    neutral_count: int = 0
    high_importance_count: int = 0
    medium_importance_count: int = 0
    low_importance_count: int = 0
    categories: Dict[str, int] = None
    sources: Dict[str, int] = None
    
    def __post_init__(self):
        if self.categories is None:
            self.categories = {}
        if self.sources is None:
            self.sources = {}


class NewsDataService:
    """æ–°é—»æ•°æ®æœåŠ¡"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self._db = None
        self._collection = None
    
    def _get_collection(self):
        """è·å–æ–°é—»æ•°æ®é›†åˆ"""
        if self._collection is None:
            self._db = get_database()
            self._collection = self._db.stock_news
        return self._collection
    
    async def save_news_data(
        self,
        news_data: Union[Dict[str, Any], List[Dict[str, Any]]],
        data_source: str,
        market: str = "CN"
    ) -> int:
        """
        ä¿å­˜æ–°é—»æ•°æ®
        
        Args:
            news_data: æ–°é—»æ•°æ®ï¼ˆå•æ¡æˆ–å¤šæ¡ï¼‰
            data_source: æ•°æ®æºæ ‡è¯†
            market: å¸‚åœºæ ‡è¯†
            
        Returns:
            ä¿å­˜çš„è®°å½•æ•°é‡
        """
        try:
            collection = self._get_collection()
            now = datetime.utcnow()
            
            # æ ‡å‡†åŒ–æ•°æ®
            if isinstance(news_data, dict):
                news_list = [news_data]
            else:
                news_list = news_data
            
            if not news_list:
                return 0
            
            # å‡†å¤‡æ‰¹é‡æ“ä½œ
            operations = []
            
            for news in news_list:
                # æ ‡å‡†åŒ–æ–°é—»æ•°æ®
                standardized_news = self._standardize_news_data(
                    news, data_source, market, now
                )
                
                # ä½¿ç”¨URLã€æ ‡é¢˜å’Œå‘å¸ƒæ—¶é—´ä½œä¸ºå”¯ä¸€æ ‡è¯†
                filter_query = {
                    "url": standardized_news["url"],
                    "title": standardized_news["title"],
                    "publish_time": standardized_news["publish_time"]
                }
                
                operations.append(
                    ReplaceOne(
                        filter_query,
                        standardized_news,
                        upsert=True
                    )
                )
            
            # æ‰§è¡Œæ‰¹é‡æ“ä½œ
            if operations:
                result = await collection.bulk_write(operations)
                saved_count = result.upserted_count + result.modified_count
                
                self.logger.info(f"ğŸ’¾ æ–°é—»æ•°æ®ä¿å­˜å®Œæˆ: {saved_count}æ¡è®°å½• (æ•°æ®æº: {data_source})")
                return saved_count
            
            return 0
            
        except BulkWriteError as e:
            # å¤„ç†æ‰¹é‡å†™å…¥é”™è¯¯ï¼Œä½†ä¸å®Œå…¨å¤±è´¥
            saved_count = len(e.details.get('writeErrors', []))
            self.logger.warning(f"âš ï¸ éƒ¨åˆ†æ–°é—»æ•°æ®ä¿å­˜å¤±è´¥: {saved_count}æ¡é”™è¯¯")
            return len(operations) - saved_count
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return 0
    
    def _standardize_news_data(
        self,
        news_data: Dict[str, Any],
        data_source: str,
        market: str,
        now: datetime
    ) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–æ–°é—»æ•°æ®"""
        
        # æå–åŸºç¡€ä¿¡æ¯
        symbol = news_data.get("symbol")
        symbols = news_data.get("symbols", [])
        
        # å¦‚æœæœ‰ä¸»è¦è‚¡ç¥¨ä»£ç ä½†symbolsä¸ºç©ºï¼Œæ·»åŠ åˆ°symbolsä¸­
        if symbol and symbol not in symbols:
            symbols = [symbol] + symbols
        
        # æ ‡å‡†åŒ–æ•°æ®ç»“æ„
        standardized = {
            # åŸºç¡€ä¿¡æ¯
            "symbol": symbol,
            "full_symbol": self._get_full_symbol(symbol, market) if symbol else None,
            "market": market,
            "symbols": symbols,
            
            # æ–°é—»å†…å®¹
            "title": news_data.get("title", ""),
            "content": news_data.get("content", ""),
            "summary": news_data.get("summary", ""),
            "url": news_data.get("url", ""),
            "source": news_data.get("source", ""),
            "author": news_data.get("author", ""),
            
            # æ—¶é—´ä¿¡æ¯
            "publish_time": self._parse_datetime(news_data.get("publish_time")),
            
            # åˆ†ç±»å’Œæ ‡ç­¾
            "category": news_data.get("category", "general"),
            "sentiment": news_data.get("sentiment", "neutral"),
            "sentiment_score": self._safe_float(news_data.get("sentiment_score")),
            "keywords": news_data.get("keywords", []),
            "importance": news_data.get("importance", "medium"),
            "language": news_data.get("language", "zh-CN"),
            
            # å…ƒæ•°æ®
            "data_source": data_source,
            "created_at": now,
            "updated_at": now,
            "version": 1
        }
        
        return standardized
    
    def _get_full_symbol(self, symbol: str, market: str) -> str:
        """è·å–å®Œæ•´è‚¡ç¥¨ä»£ç """
        if not symbol:
            return None
        
        if market == "CN":
            if len(symbol) == 6:
                if symbol.startswith(('60', '68')):
                    return f"{symbol}.SH"
                elif symbol.startswith(('00', '30')):
                    return f"{symbol}.SZ"
        
        return symbol
    
    def _parse_datetime(self, dt_value) -> Optional[datetime]:
        """è§£ææ—¥æœŸæ—¶é—´"""
        if dt_value is None:
            return None
        
        if isinstance(dt_value, datetime):
            return dt_value
        
        if isinstance(dt_value, str):
            try:
                # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                formats = [
                    "%Y-%m-%d %H:%M:%S",
                    "%Y-%m-%dT%H:%M:%S",
                    "%Y-%m-%dT%H:%M:%SZ",
                    "%Y-%m-%d",
                ]
                
                for fmt in formats:
                    try:
                        return datetime.strptime(dt_value, fmt)
                    except ValueError:
                        continue
                
                # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›å½“å‰æ—¶é—´
                self.logger.warning(f"âš ï¸ æ— æ³•è§£ææ—¥æœŸæ—¶é—´: {dt_value}")
                return datetime.utcnow()
                
            except Exception:
                return datetime.utcnow()
        
        return datetime.utcnow()
    
    def _safe_float(self, value) -> Optional[float]:
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        if value is None:
            return None
        
        try:
            return float(value)
        except (ValueError, TypeError):
            return None
    
    async def query_news(self, params: NewsQueryParams) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢æ–°é—»æ•°æ®
        
        Args:
            params: æŸ¥è¯¢å‚æ•°
            
        Returns:
            æ–°é—»æ•°æ®åˆ—è¡¨
        """
        try:
            collection = self._get_collection()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {}
            
            if params.symbol:
                query["symbol"] = params.symbol
            
            if params.symbols:
                query["symbols"] = {"$in": params.symbols}
            
            if params.start_time or params.end_time:
                time_query = {}
                if params.start_time:
                    time_query["$gte"] = params.start_time
                if params.end_time:
                    time_query["$lte"] = params.end_time
                query["publish_time"] = time_query
            
            if params.category:
                query["category"] = params.category
            
            if params.sentiment:
                query["sentiment"] = params.sentiment
            
            if params.importance:
                query["importance"] = params.importance
            
            if params.data_source:
                query["data_source"] = params.data_source
            
            if params.keywords:
                # æ–‡æœ¬æœç´¢
                query["$text"] = {"$search": " ".join(params.keywords)}
            
            # æ‰§è¡ŒæŸ¥è¯¢
            cursor = collection.find(query)
            
            # æ’åº
            cursor = cursor.sort(params.sort_by, params.sort_order)
            
            # åˆ†é¡µ
            cursor = cursor.skip(params.skip).limit(params.limit)
            
            # è·å–ç»“æœ
            results = await cursor.to_list(length=None)
            
            self.logger.info(f"ğŸ“Š æŸ¥è¯¢æ–°é—»æ•°æ®è¿”å› {len(results)} æ¡è®°å½•")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return []
    
    async def get_latest_news(
        self,
        symbol: str = None,
        limit: int = 10,
        hours_back: int = 24
    ) -> List[Dict[str, Any]]:
        """
        è·å–æœ€æ–°æ–°é—»
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œä¸ºç©ºåˆ™è·å–æ‰€æœ‰æ–°é—»
            limit: è¿”å›æ•°é‡é™åˆ¶
            hours_back: å›æº¯å°æ—¶æ•°
            
        Returns:
            æœ€æ–°æ–°é—»åˆ—è¡¨
        """
        start_time = datetime.utcnow() - timedelta(hours=hours_back)
        
        params = NewsQueryParams(
            symbol=symbol,
            start_time=start_time,
            limit=limit,
            sort_by="publish_time",
            sort_order=-1
        )
        
        return await self.query_news(params)
    
    async def get_news_statistics(
        self,
        symbol: str = None,
        start_time: datetime = None,
        end_time: datetime = None
    ) -> NewsStats:
        """
        è·å–æ–°é—»ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            
        Returns:
            æ–°é—»ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            collection = self._get_collection()
            
            # æ„å»ºåŒ¹é…æ¡ä»¶
            match_stage = {}
            
            if symbol:
                match_stage["symbol"] = symbol
            
            if start_time or end_time:
                time_query = {}
                if start_time:
                    time_query["$gte"] = start_time
                if end_time:
                    time_query["$lte"] = end_time
                match_stage["publish_time"] = time_query
            
            # èšåˆç®¡é“
            pipeline = []
            
            if match_stage:
                pipeline.append({"$match": match_stage})
            
            pipeline.extend([
                {
                    "$group": {
                        "_id": None,
                        "total_count": {"$sum": 1},
                        "positive_count": {
                            "$sum": {"$cond": [{"$eq": ["$sentiment", "positive"]}, 1, 0]}
                        },
                        "negative_count": {
                            "$sum": {"$cond": [{"$eq": ["$sentiment", "negative"]}, 1, 0]}
                        },
                        "neutral_count": {
                            "$sum": {"$cond": [{"$eq": ["$sentiment", "neutral"]}, 1, 0]}
                        },
                        "high_importance_count": {
                            "$sum": {"$cond": [{"$eq": ["$importance", "high"]}, 1, 0]}
                        },
                        "medium_importance_count": {
                            "$sum": {"$cond": [{"$eq": ["$importance", "medium"]}, 1, 0]}
                        },
                        "low_importance_count": {
                            "$sum": {"$cond": [{"$eq": ["$importance", "low"]}, 1, 0]}
                        },
                        "categories": {"$push": "$category"},
                        "sources": {"$push": "$data_source"}
                    }
                }
            ])
            
            # æ‰§è¡Œèšåˆ
            result = await collection.aggregate(pipeline).to_list(length=1)
            
            if result:
                data = result[0]
                
                # ç»Ÿè®¡åˆ†ç±»å’Œæ¥æº
                categories = {}
                for cat in data.get("categories", []):
                    categories[cat] = categories.get(cat, 0) + 1
                
                sources = {}
                for src in data.get("sources", []):
                    sources[src] = sources.get(src, 0) + 1
                
                return NewsStats(
                    total_count=data.get("total_count", 0),
                    positive_count=data.get("positive_count", 0),
                    negative_count=data.get("negative_count", 0),
                    neutral_count=data.get("neutral_count", 0),
                    high_importance_count=data.get("high_importance_count", 0),
                    medium_importance_count=data.get("medium_importance_count", 0),
                    low_importance_count=data.get("low_importance_count", 0),
                    categories=categories,
                    sources=sources
                )
            
            return NewsStats()
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–æ–°é—»ç»Ÿè®¡å¤±è´¥: {e}")
            return NewsStats()
    
    async def delete_old_news(self, days_to_keep: int = 90) -> int:
        """
        åˆ é™¤è¿‡æœŸæ–°é—»
        
        Args:
            days_to_keep: ä¿ç•™å¤©æ•°
            
        Returns:
            åˆ é™¤çš„è®°å½•æ•°é‡
        """
        try:
            collection = self._get_collection()
            
            cutoff_date = datetime.utcnow() - timedelta(days=days_to_keep)
            
            result = await collection.delete_many({
                "publish_time": {"$lt": cutoff_date}
            })
            
            deleted_count = result.deleted_count
            self.logger.info(f"ğŸ—‘ï¸ åˆ é™¤è¿‡æœŸæ–°é—»: {deleted_count}æ¡è®°å½•")
            
            return deleted_count
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ é™¤è¿‡æœŸæ–°é—»å¤±è´¥: {e}")
            return 0

    async def search_news(
        self,
        query_text: str,
        symbol: str = None,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        å…¨æ–‡æœç´¢æ–°é—»

        Args:
            query_text: æœç´¢æ–‡æœ¬
            symbol: è‚¡ç¥¨ä»£ç è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            collection = self._get_collection()

            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {"$text": {"$search": query_text}}

            if symbol:
                query["symbol"] = symbol

            # æ‰§è¡Œæœç´¢ï¼ŒæŒ‰ç›¸å…³æ€§æ’åº
            cursor = collection.find(
                query,
                {"score": {"$meta": "textScore"}}
            ).sort([("score", {"$meta": "textScore"})])

            cursor = cursor.limit(limit)
            results = await cursor.to_list(length=None)

            self.logger.info(f"ğŸ” å…¨æ–‡æœç´¢è¿”å› {len(results)} æ¡ç»“æœ")
            return results

        except Exception as e:
            self.logger.error(f"âŒ å…¨æ–‡æœç´¢å¤±è´¥: {e}")
            return []


# å…¨å±€æœåŠ¡å®ä¾‹
_service_instance = None

async def get_news_data_service() -> NewsDataService:
    """è·å–æ–°é—»æ•°æ®æœåŠ¡å®ä¾‹"""
    global _service_instance
    if _service_instance is None:
        _service_instance = NewsDataService()
        logger.info("âœ… æ–°é—»æ•°æ®æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    return _service_instance
