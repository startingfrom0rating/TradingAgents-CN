"""
ç®€åŒ–çš„è‚¡ç¥¨åˆ†ææœåŠ¡
ç›´æ¥è°ƒç”¨ç°æœ‰çš„ TradingAgents åˆ†æåŠŸèƒ½
"""

import asyncio
import uuid
import logging
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# åˆå§‹åŒ–TradingAgentsæ—¥å¿—ç³»ç»Ÿ
from tradingagents.utils.logging_init import init_logging
init_logging()

from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG
from app.models.analysis import (
    AnalysisTask, AnalysisStatus, SingleAnalysisRequest, AnalysisParameters
)
from app.models.user import PyObjectId
from bson import ObjectId
from app.core.database import get_mongo_db
from app.services.config_service import ConfigService
from app.services.memory_state_manager import get_memory_state_manager, TaskStatus
from app.services.redis_progress_tracker import RedisProgressTracker, get_progress_by_id
from app.services.progress_log_handler import register_analysis_tracker, unregister_analysis_tracker

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger("app.services.simple_analysis_service")

# é…ç½®æœåŠ¡å®ä¾‹
config_service = ConfigService()


async def get_provider_by_model_name(model_name: str) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°ä»æ•°æ®åº“é…ç½®ä¸­æŸ¥æ‰¾å¯¹åº”çš„ä¾›åº”å•†

    Args:
        model_name: æ¨¡å‹åç§°ï¼Œå¦‚ 'qwen-turbo', 'gpt-4' ç­‰

    Returns:
        str: ä¾›åº”å•†åç§°ï¼Œå¦‚ 'dashscope', 'openai' ç­‰
    """
    try:
        # ä»é…ç½®æœåŠ¡è·å–ç³»ç»Ÿé…ç½®
        system_config = await config_service.get_system_config()
        if not system_config or not system_config.llm_configs:
            logger.warning(f"âš ï¸ ç³»ç»Ÿé…ç½®ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤ä¾›åº”å•†æ˜ å°„")
            return _get_default_provider_by_model(model_name)

        # åœ¨LLMé…ç½®ä¸­æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å‹
        for llm_config in system_config.llm_configs:
            if llm_config.model_name == model_name:
                provider = llm_config.provider.value if hasattr(llm_config.provider, 'value') else str(llm_config.provider)
                logger.info(f"âœ… ä»æ•°æ®åº“æ‰¾åˆ°æ¨¡å‹ {model_name} çš„ä¾›åº”å•†: {provider}")
                return provider

        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„
        logger.warning(f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°æ¨¡å‹ {model_name}ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„")
        return _get_default_provider_by_model(model_name)

    except Exception as e:
        logger.error(f"âŒ æŸ¥æ‰¾æ¨¡å‹ä¾›åº”å•†å¤±è´¥: {e}")
        return _get_default_provider_by_model(model_name)


def _get_default_provider_by_model(model_name: str) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°è¿”å›é»˜è®¤çš„ä¾›åº”å•†æ˜ å°„
    è¿™æ˜¯ä¸€ä¸ªåå¤‡æ–¹æ¡ˆï¼Œå½“æ•°æ®åº“æŸ¥è¯¢å¤±è´¥æ—¶ä½¿ç”¨
    """
    # æ¨¡å‹åç§°åˆ°ä¾›åº”å•†çš„é»˜è®¤æ˜ å°„
    model_provider_map = {
        # é˜¿é‡Œç™¾ç‚¼ (DashScope)
        'qwen-turbo': 'dashscope',
        'qwen-plus': 'dashscope',
        'qwen-max': 'dashscope',
        'qwen-plus-latest': 'dashscope',
        'qwen-max-longcontext': 'dashscope',

        # OpenAI
        'gpt-3.5-turbo': 'openai',
        'gpt-4': 'openai',
        'gpt-4-turbo': 'openai',
        'gpt-4o': 'openai',
        'gpt-4o-mini': 'openai',

        # Google
        'gemini-pro': 'google',
        'gemini-2.0-flash': 'google',
        'gemini-2.0-flash-thinking-exp': 'google',

        # DeepSeek
        'deepseek-chat': 'deepseek',
        'deepseek-coder': 'deepseek',

        # æ™ºè°±AI
        'glm-4': 'zhipu',
        'glm-3-turbo': 'zhipu',
        'chatglm3-6b': 'zhipu'
    }

    provider = model_provider_map.get(model_name, 'dashscope')  # é»˜è®¤ä½¿ç”¨é˜¿é‡Œç™¾ç‚¼
    logger.info(f"ğŸ”§ ä½¿ç”¨é»˜è®¤æ˜ å°„: {model_name} -> {provider}")
    return provider


def create_analysis_config(
    research_depth: str,
    selected_analysts: list,
    quick_model: str,
    deep_model: str,
    llm_provider: str,
    market_type: str = "Aè‚¡"
) -> dict:
    """
    åˆ›å»ºåˆ†æé…ç½® - å®Œå…¨å¤åˆ¶webç›®å½•çš„é…ç½®é€»è¾‘

    Args:
        research_depth: ç ”ç©¶æ·±åº¦ ("å¿«é€Ÿ", "æ ‡å‡†", "æ·±åº¦")
        selected_analysts: é€‰ä¸­çš„åˆ†æå¸ˆåˆ—è¡¨
        quick_model: å¿«é€Ÿåˆ†ææ¨¡å‹
        deep_model: æ·±åº¦åˆ†ææ¨¡å‹
        llm_provider: LLMä¾›åº”å•†
        market_type: å¸‚åœºç±»å‹

    Returns:
        dict: å®Œæ•´çš„åˆ†æé…ç½®
    """
    # ä»DEFAULT_CONFIGå¼€å§‹ï¼Œå®Œå…¨å¤åˆ¶webç›®å½•çš„é€»è¾‘
    config = DEFAULT_CONFIG.copy()
    config["llm_provider"] = llm_provider
    config["deep_think_llm"] = deep_model
    config["quick_think_llm"] = quick_model

    # æ ¹æ®ç ”ç©¶æ·±åº¦è°ƒæ•´é…ç½® - æ–¹æ¡ˆCï¼šè‡ªå®šä¹‰æ˜ å°„
    if research_depth == "å¿«é€Ÿ":
        config["max_debate_rounds"] = 1
        config["max_risk_discuss_rounds"] = 1
        config["memory_enabled"] = True
        config["online_tools"] = True
        logger.info(f"ğŸ”§ [å¿«é€Ÿåˆ†æ] {market_type}ä½¿ç”¨ç»Ÿä¸€å·¥å…·ï¼Œç¡®ä¿æ•°æ®æºæ­£ç¡®å’Œç¨³å®šæ€§")

        # æ ¹æ®ä¾›åº”å•†ä¼˜åŒ–æ¨¡å‹é€‰æ‹©
        if llm_provider == "dashscope":
            config["quick_think_llm"] = "qwen-turbo"  # ä½¿ç”¨æœ€å¿«æ¨¡å‹
            config["deep_think_llm"] = "qwen-plus"
        elif llm_provider == "deepseek":
            config["quick_think_llm"] = "deepseek-chat"
            config["deep_think_llm"] = "deepseek-chat"

    elif research_depth == "æ ‡å‡†":
        config["max_debate_rounds"] = 1
        config["max_risk_discuss_rounds"] = 2
        config["memory_enabled"] = True
        config["online_tools"] = True

        if llm_provider == "dashscope":
            config["quick_think_llm"] = "qwen-plus"
            config["deep_think_llm"] = "qwen-max"
        elif llm_provider == "deepseek":
            config["quick_think_llm"] = "deepseek-chat"
            config["deep_think_llm"] = "deepseek-chat"

    elif research_depth == "æ·±åº¦":
        config["max_debate_rounds"] = 2
        config["max_risk_discuss_rounds"] = 3
        config["memory_enabled"] = True
        config["online_tools"] = True

        if llm_provider == "dashscope":
            config["quick_think_llm"] = "qwen-max"
            config["deep_think_llm"] = "qwen-max"
        elif llm_provider == "deepseek":
            config["quick_think_llm"] = "deepseek-chat"
            config["deep_think_llm"] = "deepseek-chat"

    # æ ¹æ®LLMæä¾›å•†è®¾ç½®åç«¯URL
    if llm_provider == "dashscope":
        config["backend_url"] = "https://dashscope.aliyuncs.com/api/v1"
    elif llm_provider == "deepseek":
        config["backend_url"] = "https://api.deepseek.com"
    elif llm_provider == "openai":
        config["backend_url"] = "https://api.openai.com/v1"
    elif llm_provider == "google":
        config["backend_url"] = "https://generativelanguage.googleapis.com/v1"
    elif llm_provider == "qianfan":
        config["backend_url"] = "https://aip.baidubce.com"

    # æ·»åŠ åˆ†æå¸ˆé…ç½®
    config["selected_analysts"] = selected_analysts
    config["debug"] = False

    logger.info(f"ğŸ“‹ åˆ›å»ºåˆ†æé…ç½®å®Œæˆ:")
    logger.info(f"   ç ”ç©¶æ·±åº¦: {research_depth}")
    logger.info(f"   è¾©è®ºè½®æ¬¡: {config['max_debate_rounds']}")
    logger.info(f"   é£é™©è®¨è®ºè½®æ¬¡: {config['max_risk_discuss_rounds']}")
    logger.info(f"   LLMä¾›åº”å•†: {llm_provider}")
    logger.info(f"   å¿«é€Ÿæ¨¡å‹: {config['quick_think_llm']}")
    logger.info(f"   æ·±åº¦æ¨¡å‹: {config['deep_think_llm']}")

    return config


class SimpleAnalysisService:
    """ç®€åŒ–çš„è‚¡ç¥¨åˆ†ææœåŠ¡ç±»"""

    def __init__(self):
        self._trading_graph_cache = {}
        self.memory_manager = get_memory_state_manager()
        # è¿›åº¦è·Ÿè¸ªå™¨ç¼“å­˜
        self._progress_trackers: Dict[str, RedisProgressTracker] = {}

        logger.info(f"ğŸ”§ [æœåŠ¡åˆå§‹åŒ–] SimpleAnalysisService å®ä¾‹ID: {id(self)}")
        logger.info(f"ğŸ”§ [æœåŠ¡åˆå§‹åŒ–] å†…å­˜ç®¡ç†å™¨å®ä¾‹ID: {id(self.memory_manager)}")

        # è®¾ç½® WebSocket ç®¡ç†å™¨
        try:
            from app.services.websocket_manager import get_websocket_manager
            self.memory_manager.set_websocket_manager(get_websocket_manager())
        except ImportError:
            logger.warning("âš ï¸ WebSocket ç®¡ç†å™¨ä¸å¯ç”¨")
    
    def _convert_user_id(self, user_id: str) -> PyObjectId:
        """å°†å­—ç¬¦ä¸²ç”¨æˆ·IDè½¬æ¢ä¸ºPyObjectId"""
        try:
            logger.info(f"ğŸ”„ å¼€å§‹è½¬æ¢ç”¨æˆ·ID: {user_id} (ç±»å‹: {type(user_id)})")
            
            # å¦‚æœæ˜¯adminç”¨æˆ·ï¼Œä½¿ç”¨å›ºå®šçš„ObjectId
            if user_id == "admin":
                admin_object_id = ObjectId("507f1f77bcf86cd799439011")
                logger.info(f"ğŸ”„ è½¬æ¢adminç”¨æˆ·ID: {user_id} -> {admin_object_id}")
                return PyObjectId(admin_object_id)
            else:
                # å°è¯•å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºObjectId
                object_id = ObjectId(user_id)
                logger.info(f"ğŸ”„ è½¬æ¢ç”¨æˆ·ID: {user_id} -> {object_id}")
                return PyObjectId(object_id)
        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ·IDè½¬æ¢å¤±è´¥: {user_id} -> {e}")
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„ObjectId
            new_object_id = ObjectId()
            logger.warning(f"âš ï¸ ç”Ÿæˆæ–°çš„ç”¨æˆ·ID: {new_object_id}")
            return PyObjectId(new_object_id)
    
    def _get_trading_graph(self, config: Dict[str, Any]) -> TradingAgentsGraph:
        """è·å–æˆ–åˆ›å»ºTradingAgentså®ä¾‹ - å®Œå…¨å¤åˆ¶webç›®å½•çš„åˆ›å»ºæ–¹å¼"""
        config_key = str(sorted(config.items()))

        if config_key not in self._trading_graph_cache:
            logger.info(f"åˆ›å»ºæ–°çš„TradingAgentså®ä¾‹...")

            # ç›´æ¥ä½¿ç”¨å®Œæ•´é…ç½®ï¼Œä¸å†åˆå¹¶DEFAULT_CONFIGï¼ˆå› ä¸ºcreate_analysis_configå·²ç»å¤„ç†äº†ï¼‰
            # è¿™ä¸webç›®å½•çš„æ–¹å¼ä¸€è‡´
            self._trading_graph_cache[config_key] = TradingAgentsGraph(
                selected_analysts=config.get("selected_analysts", ["market", "fundamentals"]),
                debug=config.get("debug", False),
                config=config
            )

            logger.info(f"âœ… TradingAgentså®ä¾‹åˆ›å»ºæˆåŠŸ")

        return self._trading_graph_cache[config_key]

    async def create_analysis_task(
        self,
        user_id: str,
        request: SingleAnalysisRequest
    ) -> Dict[str, Any]:
        """åˆ›å»ºåˆ†æä»»åŠ¡ï¼ˆç«‹å³è¿”å›ï¼Œä¸æ‰§è¡Œåˆ†æï¼‰"""
        try:
            # ç”Ÿæˆä»»åŠ¡ID
            task_id = str(uuid.uuid4())

            logger.info(f"ğŸ“ åˆ›å»ºåˆ†æä»»åŠ¡: {task_id} - {request.stock_code}")
            logger.info(f"ğŸ” å†…å­˜ç®¡ç†å™¨å®ä¾‹ID: {id(self.memory_manager)}")

            # åœ¨å†…å­˜ä¸­åˆ›å»ºä»»åŠ¡çŠ¶æ€
            task_state = await self.memory_manager.create_task(
                task_id=task_id,
                user_id=user_id,
                stock_code=request.stock_code,
                parameters=request.parameters.model_dump() if request.parameters else {}
            )

            logger.info(f"âœ… ä»»åŠ¡çŠ¶æ€å·²åˆ›å»º: {task_state.task_id}")

            # ç«‹å³éªŒè¯ä»»åŠ¡æ˜¯å¦å¯ä»¥æŸ¥è¯¢åˆ°
            verify_task = await self.memory_manager.get_task(task_id)
            if verify_task:
                logger.info(f"âœ… ä»»åŠ¡åˆ›å»ºéªŒè¯æˆåŠŸ: {verify_task.task_id}")
            else:
                logger.error(f"âŒ ä»»åŠ¡åˆ›å»ºéªŒè¯å¤±è´¥: æ— æ³•æŸ¥è¯¢åˆ°åˆšåˆ›å»ºçš„ä»»åŠ¡ {task_id}")

            return {
                "task_id": task_id,
                "status": "pending",
                "message": "ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…æ‰§è¡Œ"
            }

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºåˆ†æä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def execute_analysis_background(
        self,
        task_id: str,
        user_id: str,
        request: SingleAnalysisRequest
    ):
        """åœ¨åå°æ‰§è¡Œåˆ†æä»»åŠ¡"""
        progress_tracker = None
        try:
            logger.info(f"ğŸš€ å¼€å§‹åå°æ‰§è¡Œåˆ†æä»»åŠ¡: {task_id}")

            # åˆ›å»ºRedisè¿›åº¦è·Ÿè¸ªå™¨
            progress_tracker = RedisProgressTracker(
                task_id=task_id,
                analysts=request.parameters.selected_analysts or ["market", "fundamentals"],
                research_depth=request.parameters.research_depth or "æ ‡å‡†",
                llm_provider="dashscope"
            )

            # ç¼“å­˜è¿›åº¦è·Ÿè¸ªå™¨
            self._progress_trackers[task_id] = progress_tracker

            # æ³¨å†Œåˆ°æ—¥å¿—ç›‘æ§
            register_analysis_tracker(task_id, progress_tracker)

            # åˆå§‹åŒ–è¿›åº¦
            progress_tracker.update_progress("ğŸš€ å¼€å§‹è‚¡ç¥¨åˆ†æ")

            # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            await self.memory_manager.update_task_status(
                task_id=task_id,
                status=TaskStatus.RUNNING,
                progress=10,
                message="åˆ†æå¼€å§‹...",
                current_step="initialization"
            )

            # æ•°æ®å‡†å¤‡é˜¶æ®µ
            progress_tracker.update_progress("ğŸ”§ æ£€æŸ¥ç¯å¢ƒé…ç½®")
            await self.memory_manager.update_task_status(
                task_id=task_id,
                status=TaskStatus.RUNNING,
                progress=20,
                message="å‡†å¤‡åˆ†ææ•°æ®...",
                current_step="data_preparation"
            )

            # æ‰§è¡Œå®é™…çš„åˆ†æ
            result = await self._execute_analysis_sync(task_id, user_id, request, progress_tracker)

            # æ ‡è®°è¿›åº¦è·Ÿè¸ªå™¨å®Œæˆ
            progress_tracker.mark_completed("âœ… åˆ†æå®Œæˆ")

            # ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶å’Œæ•°æ®åº“
            try:
                logger.info(f"ğŸ’¾ å¼€å§‹ä¿å­˜åˆ†æç»“æœ: {task_id}")
                await self._save_analysis_results_complete(task_id, result)
                logger.info(f"âœ… åˆ†æç»“æœä¿å­˜å®Œæˆ: {task_id}")
            except Exception as save_error:
                logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {task_id} - {save_error}")
                # ä¿å­˜å¤±è´¥ä¸å½±å“åˆ†æå®ŒæˆçŠ¶æ€

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥å³å°†ä¿å­˜åˆ°å†…å­˜çš„result
            logger.info(f"ğŸ” [DEBUG] å³å°†ä¿å­˜åˆ°å†…å­˜çš„resulté”®: {list(result.keys())}")
            logger.info(f"ğŸ” [DEBUG] å³å°†ä¿å­˜åˆ°å†…å­˜çš„decision: {bool(result.get('decision'))}")
            if result.get('decision'):
                logger.info(f"ğŸ” [DEBUG] å³å°†ä¿å­˜çš„decisionå†…å®¹: {result['decision']}")

            # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
            await self.memory_manager.update_task_status(
                task_id=task_id,
                status=TaskStatus.COMPLETED,
                progress=100,
                message="åˆ†æå®Œæˆ",
                current_step="completed",
                result_data=result
            )

            logger.info(f"âœ… åå°åˆ†æä»»åŠ¡å®Œæˆ: {task_id}")

        except Exception as e:
            logger.error(f"âŒ åå°åˆ†æä»»åŠ¡å¤±è´¥: {task_id} - {e}")

            # æ ‡è®°è¿›åº¦è·Ÿè¸ªå™¨å¤±è´¥
            if progress_tracker:
                progress_tracker.mark_failed(str(e))

            # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
            await self.memory_manager.update_task_status(
                task_id=task_id,
                status=TaskStatus.FAILED,
                progress=0,
                message="åˆ†æå¤±è´¥",
                current_step="failed",
                error_message=str(e)
            )
        finally:
            # æ¸…ç†è¿›åº¦è·Ÿè¸ªå™¨ç¼“å­˜
            if task_id in self._progress_trackers:
                del self._progress_trackers[task_id]

            # ä»æ—¥å¿—ç›‘æ§ä¸­æ³¨é”€
            unregister_analysis_tracker(task_id)

    async def _execute_analysis_sync(
        self,
        task_id: str,
        user_id: str,
        request: SingleAnalysisRequest,
        progress_tracker: Optional[RedisProgressTracker] = None
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡Œåˆ†æï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰"""
        import concurrent.futures

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥åˆ†æ
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            result = await loop.run_in_executor(
                executor,
                self._run_analysis_sync,
                task_id,
                user_id,
                request,
                progress_tracker
            )
        return result

    def _run_analysis_sync(
        self,
        task_id: str,
        user_id: str,
        request: SingleAnalysisRequest,
        progress_tracker: Optional[RedisProgressTracker] = None
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡Œåˆ†æçš„å…·ä½“å®ç°"""
        try:
            # åœ¨çº¿ç¨‹ä¸­é‡æ–°åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
            from tradingagents.utils.logging_init import init_logging, get_logger
            init_logging()
            thread_logger = get_logger('analysis_thread')

            thread_logger.info(f"ğŸ”„ [çº¿ç¨‹æ± ] å¼€å§‹æ‰§è¡Œåˆ†æ: {task_id} - {request.stock_code}")
            logger.info(f"ğŸ”„ [çº¿ç¨‹æ± ] å¼€å§‹æ‰§è¡Œåˆ†æ: {task_id} - {request.stock_code}")

            # å¦‚æœæœ‰è¿›åº¦è·Ÿè¸ªå™¨ï¼Œæ›´æ–°è¿›åº¦
            if progress_tracker:
                progress_tracker.update_progress("âš™ï¸ é…ç½®åˆ†æå‚æ•°")

            # å¼‚æ­¥æ›´æ–°è¿›åº¦ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è°ƒç”¨ï¼‰
            def update_progress_sync(progress: int, message: str, step: str):
                """åœ¨çº¿ç¨‹æ± ä¸­åŒæ­¥æ›´æ–°è¿›åº¦"""
                try:
                    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æ¥æ‰§è¡Œå¼‚æ­¥æ“ä½œ
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        loop.run_until_complete(
                            self.memory_manager.update_task_status(
                                task_id=task_id,
                                status=TaskStatus.RUNNING,
                                progress=progress,
                                message=message,
                                current_step=step
                            )
                        )
                    finally:
                        loop.close()
                except Exception as e:
                    logger.warning(f"âš ï¸ è¿›åº¦æ›´æ–°å¤±è´¥: {e}")

            # é…ç½®é˜¶æ®µ
            if progress_tracker:
                progress_tracker.update_progress("âš™ï¸ é…ç½®åˆ†æå‚æ•°")
            update_progress_sync(30, "é…ç½®åˆ†æå‚æ•°...", "configuration")

            # åˆ›å»ºåˆ†æé…ç½®
            config = create_analysis_config(
                research_depth=request.parameters.research_depth if request.parameters else 2,
                selected_analysts=request.parameters.selected_analysts if request.parameters else ["market", "fundamentals"],
                quick_model="qwen-turbo",
                deep_model="qwen-plus",
                llm_provider="dashscope",
                market_type="Aè‚¡"
            )

            # åˆå§‹åŒ–åˆ†æå¼•æ“
            if progress_tracker:
                progress_tracker.update_progress("ğŸš€ åˆå§‹åŒ–AIåˆ†æå¼•æ“")
            update_progress_sync(40, "åˆå§‹åŒ–åˆ†æå¼•æ“...", "engine_initialization")
            trading_graph = self._get_trading_graph(config)

            # å¼€å§‹åˆ†æ
            if progress_tracker:
                progress_tracker.update_progress("ğŸ“Š å¼€å§‹æ™ºèƒ½ä½“åˆ†æ")
            update_progress_sync(50, "å¼€å§‹è‚¡ç¥¨åˆ†æ...", "analysis_execution")
            start_time = datetime.now()
            analysis_date = datetime.now().strftime("%Y-%m-%d")

            # è°ƒç”¨åˆ†ææ–¹æ³• - æ·»åŠ è¿›åº¦æ¨¡æ‹Ÿ
            if progress_tracker:
                progress_tracker.update_progress("ğŸ¤– æ‰§è¡Œå¤šæ™ºèƒ½ä½“åä½œåˆ†æ")
            update_progress_sync(60, "æ‰§è¡Œæ™ºèƒ½ä½“åˆ†æ...", "agent_analysis")

            # å¯åŠ¨ä¸€ä¸ªå¼‚æ­¥ä»»åŠ¡æ¥æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
            import threading
            import time

            def simulate_progress():
                """æ¨¡æ‹ŸTradingAgentså†…éƒ¨è¿›åº¦"""
                try:
                    if not progress_tracker:
                        return

                    # åˆ†æå¸ˆé˜¶æ®µ - æ ¹æ®é€‰æ‹©çš„åˆ†æå¸ˆæ•°é‡åŠ¨æ€è°ƒæ•´
                    analysts = request.parameters.selected_analysts if request.parameters else ["market", "fundamentals"]

                    # æ¨¡æ‹Ÿåˆ†æå¸ˆæ‰§è¡Œ
                    for i, analyst in enumerate(analysts):
                        time.sleep(15)  # æ¯ä¸ªåˆ†æå¸ˆå¤§çº¦15ç§’
                        if analyst == "market":
                            progress_tracker.update_progress("ğŸ“Š å¸‚åœºåˆ†æå¸ˆæ­£åœ¨åˆ†æ")
                        elif analyst == "fundamentals":
                            progress_tracker.update_progress("ğŸ’¼ åŸºæœ¬é¢åˆ†æå¸ˆæ­£åœ¨åˆ†æ")
                        elif analyst == "news":
                            progress_tracker.update_progress("ğŸ“° æ–°é—»åˆ†æå¸ˆæ­£åœ¨åˆ†æ")
                        elif analyst == "social":
                            progress_tracker.update_progress("ğŸ’¬ ç¤¾äº¤åª’ä½“åˆ†æå¸ˆæ­£åœ¨åˆ†æ")

                    # ç ”ç©¶å›¢é˜Ÿé˜¶æ®µ
                    time.sleep(10)
                    progress_tracker.update_progress("ğŸ‚ çœ‹æ¶¨ç ”ç©¶å‘˜æ„å»ºè®ºæ®")

                    time.sleep(8)
                    progress_tracker.update_progress("ğŸ» çœ‹è·Œç ”ç©¶å‘˜è¯†åˆ«é£é™©")

                    # è¾©è®ºé˜¶æ®µ
                    research_depth = request.parameters.research_depth if request.parameters else "å¿«é€Ÿ"
                    debate_rounds = 1 if research_depth == "å¿«é€Ÿ" else (2 if research_depth == "æ ‡å‡†" else 3)

                    for round_num in range(debate_rounds):
                        time.sleep(12)
                        progress_tracker.update_progress(f"ğŸ¯ ç ”ç©¶è¾©è®º ç¬¬{round_num+1}è½®")

                    time.sleep(8)
                    progress_tracker.update_progress("ğŸ‘” ç ”ç©¶ç»ç†å½¢æˆå…±è¯†")

                    # äº¤æ˜“å‘˜é˜¶æ®µ
                    time.sleep(10)
                    progress_tracker.update_progress("ğŸ’¼ äº¤æ˜“å‘˜åˆ¶å®šç­–ç•¥")

                    # é£é™©ç®¡ç†é˜¶æ®µ
                    time.sleep(8)
                    progress_tracker.update_progress("ğŸ”¥ æ¿€è¿›é£é™©è¯„ä¼°")

                    time.sleep(6)
                    progress_tracker.update_progress("ğŸ›¡ï¸ ä¿å®ˆé£é™©è¯„ä¼°")

                    time.sleep(6)
                    progress_tracker.update_progress("âš–ï¸ ä¸­æ€§é£é™©è¯„ä¼°")

                    time.sleep(8)
                    progress_tracker.update_progress("ğŸ¯ é£é™©ç»ç†åˆ¶å®šç­–ç•¥")

                    # æœ€ç»ˆé˜¶æ®µ
                    time.sleep(5)
                    progress_tracker.update_progress("ğŸ“¡ ä¿¡å·å¤„ç†")

                except Exception as e:
                    logger.warning(f"âš ï¸ è¿›åº¦æ¨¡æ‹Ÿå¤±è´¥: {e}")

            # å¯åŠ¨è¿›åº¦æ¨¡æ‹Ÿçº¿ç¨‹
            progress_thread = threading.Thread(target=simulate_progress, daemon=True)
            progress_thread.start()

            # æ‰§è¡Œå®é™…åˆ†æ
            state, decision = trading_graph.propagate(request.stock_code, analysis_date)

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥decisionçš„ç»“æ„
            logger.info(f"ğŸ” [DEBUG] Decisionç±»å‹: {type(decision)}")
            logger.info(f"ğŸ” [DEBUG] Decisionå†…å®¹: {decision}")
            if isinstance(decision, dict):
                logger.info(f"ğŸ” [DEBUG] Decisioné”®: {list(decision.keys())}")
            elif hasattr(decision, '__dict__'):
                logger.info(f"ğŸ” [DEBUG] Decisionå±æ€§: {list(vars(decision).keys())}")

            # å¤„ç†ç»“æœ
            if progress_tracker:
                progress_tracker.update_progress("ğŸ“Š å¤„ç†åˆ†æç»“æœ")
            update_progress_sync(90, "å¤„ç†åˆ†æç»“æœ...", "result_processing")

            execution_time = (datetime.now() - start_time).total_seconds()

            # ä»stateä¸­æå–reportså­—æ®µ
            reports = {}
            try:
                # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„æŠ¥å‘Šå­—æ®µ
                report_fields = [
                    'market_report',
                    'sentiment_report',
                    'news_report',
                    'fundamentals_report',
                    'investment_plan',
                    'trader_investment_plan',
                    'final_trade_decision'
                ]

                # ä»stateä¸­æå–æŠ¥å‘Šå†…å®¹
                for field in report_fields:
                    if hasattr(state, field):
                        value = getattr(state, field, "")
                    elif isinstance(state, dict) and field in state:
                        value = state[field]
                    else:
                        value = ""

                    if isinstance(value, str) and len(value.strip()) > 10:  # åªä¿å­˜æœ‰å®é™…å†…å®¹çš„æŠ¥å‘Š
                        reports[field] = value.strip()

                # å¤„ç†å¤æ‚çš„è¾©è®ºçŠ¶æ€æŠ¥å‘Š
                if hasattr(state, 'investment_debate_state') or (isinstance(state, dict) and 'investment_debate_state' in state):
                    debate_state = getattr(state, 'investment_debate_state', None) if hasattr(state, 'investment_debate_state') else state.get('investment_debate_state')
                    if debate_state:
                        if hasattr(debate_state, 'judge_decision'):
                            decision_content = getattr(debate_state, 'judge_decision', "")
                        elif isinstance(debate_state, dict) and 'judge_decision' in debate_state:
                            decision_content = debate_state['judge_decision']
                        else:
                            decision_content = str(debate_state)

                        if decision_content and len(decision_content.strip()) > 10:
                            reports['research_team_decision'] = decision_content.strip()

                if hasattr(state, 'risk_debate_state') or (isinstance(state, dict) and 'risk_debate_state' in state):
                    risk_state = getattr(state, 'risk_debate_state', None) if hasattr(state, 'risk_debate_state') else state.get('risk_debate_state')
                    if risk_state:
                        if hasattr(risk_state, 'judge_decision'):
                            risk_decision = getattr(risk_state, 'judge_decision', "")
                        elif isinstance(risk_state, dict) and 'judge_decision' in risk_state:
                            risk_decision = risk_state['judge_decision']
                        else:
                            risk_decision = str(risk_state)

                        if risk_decision and len(risk_decision.strip()) > 10:
                            reports['risk_management_decision'] = risk_decision.strip()

                logger.info(f"ğŸ“Š ä»stateä¸­æå–åˆ° {len(reports)} ä¸ªæŠ¥å‘Š: {list(reports.keys())}")

            except Exception as e:
                logger.warning(f"âš ï¸ æå–reportsæ—¶å‡ºé”™: {e}")
                # é™çº§åˆ°ä»detailed_analysisæå–
                try:
                    if isinstance(decision, dict):
                        for key, value in decision.items():
                            if isinstance(value, str) and len(value) > 50:
                                reports[key] = value
                        logger.info(f"ğŸ“Š é™çº§ï¼šä»decisionä¸­æå–åˆ° {len(reports)} ä¸ªæŠ¥å‘Š")
                except Exception as fallback_error:
                    logger.warning(f"âš ï¸ é™çº§æå–ä¹Ÿå¤±è´¥: {fallback_error}")

            # ğŸ”¥ æ ¼å¼åŒ–decisionæ•°æ®ï¼ˆå‚è€ƒwebç›®å½•çš„å®ç°ï¼‰
            formatted_decision = {}
            try:
                if isinstance(decision, dict):
                    # å¤„ç†ç›®æ ‡ä»·æ ¼
                    target_price = decision.get('target_price')
                    if target_price is not None and target_price != 'N/A':
                        try:
                            if isinstance(target_price, str):
                                # ç§»é™¤è´§å¸ç¬¦å·å’Œç©ºæ ¼
                                clean_price = target_price.replace('$', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                                target_price = float(clean_price) if clean_price and clean_price != 'None' else None
                            elif isinstance(target_price, (int, float)):
                                target_price = float(target_price)
                            else:
                                target_price = None
                        except (ValueError, TypeError):
                            target_price = None
                    else:
                        target_price = None

                    # å°†è‹±æ–‡æŠ•èµ„å»ºè®®è½¬æ¢ä¸ºä¸­æ–‡
                    action_translation = {
                        'BUY': 'ä¹°å…¥',
                        'SELL': 'å–å‡º',
                        'HOLD': 'æŒæœ‰',
                        'buy': 'ä¹°å…¥',
                        'sell': 'å–å‡º',
                        'hold': 'æŒæœ‰'
                    }
                    action = decision.get('action', 'æŒæœ‰')
                    chinese_action = action_translation.get(action, action)

                    formatted_decision = {
                        'action': chinese_action,
                        'confidence': decision.get('confidence', 0.5),
                        'risk_score': decision.get('risk_score', 0.3),
                        'target_price': target_price,
                        'reasoning': decision.get('reasoning', 'æš‚æ— åˆ†ææ¨ç†')
                    }

                    logger.info(f"ğŸ¯ [DEBUG] æ ¼å¼åŒ–åçš„decision: {formatted_decision}")
                else:
                    # å¤„ç†å…¶ä»–ç±»å‹
                    formatted_decision = {
                        'action': 'æŒæœ‰',
                        'confidence': 0.5,
                        'risk_score': 0.3,
                        'target_price': None,
                        'reasoning': 'æš‚æ— åˆ†ææ¨ç†'
                    }
                    logger.warning(f"âš ï¸ Decisionä¸æ˜¯å­—å…¸ç±»å‹: {type(decision)}")
            except Exception as e:
                logger.error(f"âŒ æ ¼å¼åŒ–decisionå¤±è´¥: {e}")
                formatted_decision = {
                    'action': 'æŒæœ‰',
                    'confidence': 0.5,
                    'risk_score': 0.3,
                    'target_price': None,
                    'reasoning': 'æš‚æ— åˆ†ææ¨ç†'
                }

            # ğŸ”¥ æŒ‰ç…§webç›®å½•çš„æ–¹å¼ç”Ÿæˆsummaryå’Œrecommendation
            summary = ""
            recommendation = ""

            # 1. ä¼˜å…ˆä»reportsä¸­çš„final_trade_decisionæå–summaryï¼ˆä¸webç›®å½•ä¿æŒä¸€è‡´ï¼‰
            if isinstance(reports, dict) and 'final_trade_decision' in reports:
                final_decision_content = reports['final_trade_decision']
                if isinstance(final_decision_content, str) and len(final_decision_content) > 50:
                    # æå–å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦ï¼ˆä¸webç›®å½•å®Œå…¨ä¸€è‡´ï¼‰
                    summary = final_decision_content[:200].replace('#', '').replace('*', '').strip()
                    if len(final_decision_content) > 200:
                        summary += "..."
                    logger.info(f"ğŸ“ [SUMMARY] ä»final_trade_decisionæå–æ‘˜è¦: {len(summary)}å­—ç¬¦")

            # 2. å¦‚æœæ²¡æœ‰final_trade_decisionï¼Œä»stateä¸­æå–
            if not summary and isinstance(state, dict):
                final_decision = state.get('final_trade_decision', '')
                if isinstance(final_decision, str) and len(final_decision) > 50:
                    summary = final_decision[:200].replace('#', '').replace('*', '').strip()
                    if len(final_decision) > 200:
                        summary += "..."
                    logger.info(f"ğŸ“ [SUMMARY] ä»state.final_trade_decisionæå–æ‘˜è¦: {len(summary)}å­—ç¬¦")

            # 3. ç”Ÿæˆrecommendationï¼ˆä»decisionçš„reasoningï¼‰
            if isinstance(formatted_decision, dict):
                action = formatted_decision.get('action', 'æŒæœ‰')
                target_price = formatted_decision.get('target_price')
                reasoning = formatted_decision.get('reasoning', '')

                # ç”ŸæˆæŠ•èµ„å»ºè®®
                recommendation = f"æŠ•èµ„å»ºè®®ï¼š{action}ã€‚"
                if target_price:
                    recommendation += f"ç›®æ ‡ä»·æ ¼ï¼š{target_price}å…ƒã€‚"
                if reasoning:
                    recommendation += f"å†³ç­–ä¾æ®ï¼š{reasoning}"
                logger.info(f"ğŸ’¡ [RECOMMENDATION] ç”ŸæˆæŠ•èµ„å»ºè®®: {len(recommendation)}å­—ç¬¦")

            # 4. å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œä»å…¶ä»–æŠ¥å‘Šä¸­æå–
            if not summary and isinstance(reports, dict):
                # å°è¯•ä»å…¶ä»–æŠ¥å‘Šä¸­æå–æ‘˜è¦
                for report_name, content in reports.items():
                    if isinstance(content, str) and len(content) > 100:
                        summary = content[:200].replace('#', '').replace('*', '').strip()
                        if len(content) > 200:
                            summary += "..."
                        logger.info(f"ğŸ“ [SUMMARY] ä»{report_name}æå–æ‘˜è¦: {len(summary)}å­—ç¬¦")
                        break

            # 5. æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
            if not summary:
                summary = f"å¯¹{request.stock_code}çš„åˆ†æå·²å®Œæˆï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Šã€‚"
                logger.warning(f"âš ï¸ [SUMMARY] ä½¿ç”¨å¤‡ç”¨æ‘˜è¦")

            if not recommendation:
                recommendation = f"è¯·å‚è€ƒè¯¦ç»†åˆ†ææŠ¥å‘Šåšå‡ºæŠ•èµ„å†³ç­–ã€‚"
                logger.warning(f"âš ï¸ [RECOMMENDATION] ä½¿ç”¨å¤‡ç”¨å»ºè®®")

            # æ„å»ºç»“æœ
            result = {
                "analysis_id": str(uuid.uuid4()),
                "stock_code": request.stock_code,
                "stock_symbol": request.stock_code,  # æ·»åŠ stock_symbolå­—æ®µä»¥ä¿æŒå…¼å®¹æ€§
                "analysis_date": analysis_date,
                "summary": summary,
                "recommendation": recommendation,
                "confidence_score": formatted_decision.get("confidence", 0.0) if isinstance(formatted_decision, dict) else 0.0,
                "risk_level": "ä¸­ç­‰",  # å¯ä»¥æ ¹æ®risk_scoreè®¡ç®—
                "key_points": [],  # å¯ä»¥ä»reasoningä¸­æå–å…³é”®ç‚¹
                "detailed_analysis": decision,
                "execution_time": execution_time,
                "tokens_used": decision.get("tokens_used", 0) if isinstance(decision, dict) else 0,
                "state": state,
                # æ·»åŠ åˆ†æå¸ˆä¿¡æ¯
                "analysts": request.parameters.selected_analysts if request.parameters else [],
                "research_depth": request.parameters.research_depth if request.parameters else "å¿«é€Ÿ",
                # æ·»åŠ æå–çš„æŠ¥å‘Šå†…å®¹
                "reports": reports,
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ æ ¼å¼åŒ–åçš„decisionå­—æ®µï¼
                "decision": formatted_decision
            }

            logger.info(f"âœ… [çº¿ç¨‹æ± ] åˆ†æå®Œæˆ: {task_id} - è€—æ—¶{execution_time:.2f}ç§’")

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥è¿”å›çš„resultç»“æ„
            logger.info(f"ğŸ” [DEBUG] è¿”å›resultçš„é”®: {list(result.keys())}")
            logger.info(f"ğŸ” [DEBUG] è¿”å›resultä¸­æœ‰decision: {bool(result.get('decision'))}")
            if result.get('decision'):
                decision = result['decision']
                logger.info(f"ğŸ” [DEBUG] è¿”å›decisionå†…å®¹: {decision}")

            return result

        except Exception as e:
            logger.error(f"âŒ [çº¿ç¨‹æ± ] åˆ†ææ‰§è¡Œå¤±è´¥: {task_id} - {e}")
            raise

    async def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        logger.info(f"ğŸ” æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€: {task_id}")
        logger.info(f"ğŸ” å½“å‰æœåŠ¡å®ä¾‹ID: {id(self)}")
        logger.info(f"ğŸ” å†…å­˜ç®¡ç†å™¨å®ä¾‹ID: {id(self.memory_manager)}")

        # å¼ºåˆ¶ä½¿ç”¨å…¨å±€å†…å­˜ç®¡ç†å™¨å®ä¾‹ï¼ˆä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼‰
        global_memory_manager = get_memory_state_manager()
        logger.info(f"ğŸ” å…¨å±€å†…å­˜ç®¡ç†å™¨å®ä¾‹ID: {id(global_memory_manager)}")

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = await global_memory_manager.get_statistics()
        logger.info(f"ğŸ“Š å†…å­˜ä¸­ä»»åŠ¡ç»Ÿè®¡: {stats}")

        result = await global_memory_manager.get_task_dict(task_id)
        if result:
            logger.info(f"âœ… æ‰¾åˆ°ä»»åŠ¡: {task_id} - çŠ¶æ€: {result.get('status')}")

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥ä»å†…å­˜è·å–çš„result_data
            result_data = result.get('result_data')
            logger.info(f"ğŸ” [GET_STATUS] result_dataå­˜åœ¨: {bool(result_data)}")
            if result_data:
                logger.info(f"ğŸ” [GET_STATUS] result_dataé”®: {list(result_data.keys())}")
                logger.info(f"ğŸ” [GET_STATUS] result_dataä¸­æœ‰decision: {bool(result_data.get('decision'))}")
                if result_data.get('decision'):
                    logger.info(f"ğŸ” [GET_STATUS] decisionå†…å®¹: {result_data['decision']}")
            else:
                logger.warning(f"âš ï¸ [GET_STATUS] result_dataä¸ºç©ºæˆ–ä¸å­˜åœ¨")

            # ä¼˜å…ˆä»Redisè·å–è¯¦ç»†è¿›åº¦ä¿¡æ¯
            redis_progress = get_progress_by_id(task_id)
            if redis_progress:
                logger.info(f"ğŸ“Š [Redisè¿›åº¦] è·å–åˆ°è¯¦ç»†è¿›åº¦: {task_id}")
                # åˆå¹¶Redisè¿›åº¦æ•°æ®
                result.update({
                    'progress': redis_progress.get('progress_percentage', result.get('progress', 0)),
                    'current_step': redis_progress.get('current_step_name', result.get('current_step', '')),
                    'message': redis_progress.get('last_message', result.get('message', '')),
                    'elapsed_time': redis_progress.get('elapsed_time', 0),
                    'remaining_time': redis_progress.get('remaining_time', 0),
                    'steps': redis_progress.get('steps', []),
                    'start_time': result.get('start_time'),  # ä¿æŒåŸæœ‰æ ¼å¼
                    'last_update': redis_progress.get('last_update', result.get('start_time'))
                })
            else:
                # å¦‚æœRedisä¸­æ²¡æœ‰ï¼Œå°è¯•ä»å†…å­˜ä¸­çš„è¿›åº¦è·Ÿè¸ªå™¨è·å–
                if task_id in self._progress_trackers:
                    progress_tracker = self._progress_trackers[task_id]
                    progress_data = progress_tracker.to_dict()

                    # åˆå¹¶è¿›åº¦è·Ÿè¸ªå™¨çš„è¯¦ç»†ä¿¡æ¯
                    result.update({
                        'progress': progress_data['progress'],
                        'current_step': progress_data['current_step'],
                        'message': progress_data['message'],
                        'elapsed_time': progress_data['elapsed_time'],
                        'remaining_time': progress_data['remaining_time'],
                        'estimated_total_time': progress_data.get('estimated_total_time', 0),
                        'steps': progress_data['steps'],
                        'start_time': progress_data['start_time'],
                        'last_update': progress_data['last_update']
                    })
                    logger.info(f"ğŸ“Š åˆå¹¶å†…å­˜è¿›åº¦è·Ÿè¸ªå™¨æ•°æ®: {task_id}")
                else:
                    logger.info(f"âš ï¸ æœªæ‰¾åˆ°è¿›åº¦ä¿¡æ¯: {task_id}")
        else:
            logger.warning(f"âŒ æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}")

        return result

    async def list_user_tasks(
        self,
        user_id: str,
        status: Optional[str] = None,
        limit: int = 20,
        offset: int = 0
    ) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨"""
        task_status = None
        if status:
            try:
                task_status = TaskStatus(status)
            except ValueError:
                pass

        return await self.memory_manager.list_user_tasks(
            user_id=user_id,
            status=task_status,
            limit=limit,
            offset=offset
        )


    

    
    async def _update_task_status(
        self, 
        task_id: str, 
        status: AnalysisStatus, 
        progress: int, 
        error_message: str = None
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        try:
            db = get_mongo_db()
            update_data = {
                "status": status,
                "progress": progress,
                "updated_at": datetime.utcnow()
            }
            
            if status == AnalysisStatus.PROCESSING and progress == 10:
                update_data["started_at"] = datetime.utcnow()
            elif status == AnalysisStatus.COMPLETED:
                update_data["completed_at"] = datetime.utcnow()
            elif status == AnalysisStatus.FAILED:
                update_data["last_error"] = error_message
                update_data["completed_at"] = datetime.utcnow()
            
            await db.analysis_tasks.update_one(
                {"task_id": task_id},
                {"$set": update_data}
            )
            
            logger.debug(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: {task_id} -> {status} ({progress}%)")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {task_id} - {e}")
    
    async def _save_analysis_result(self, task_id: str, result: Dict[str, Any]):
        """ä¿å­˜åˆ†æç»“æœï¼ˆåŸå§‹æ–¹æ³•ï¼‰"""
        try:
            db = get_mongo_db()
            await db.analysis_tasks.update_one(
                {"task_id": task_id},
                {"$set": {"result": result}}
            )
            logger.debug(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {task_id}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {task_id} - {e}")

    async def _save_analysis_result_web_style(self, task_id: str, result: Dict[str, Any]):
        """ä¿å­˜åˆ†æç»“æœ - é‡‡ç”¨webç›®å½•çš„æ–¹å¼ï¼Œä¿å­˜åˆ°analysis_reportsé›†åˆ"""
        try:
            db = get_mongo_db()

            # ç”Ÿæˆåˆ†æIDï¼ˆä¸webç›®å½•ä¿æŒä¸€è‡´ï¼‰
            from datetime import datetime
            timestamp = datetime.utcnow()
            stock_symbol = result.get('stock_symbol') or result.get('stock_code', 'UNKNOWN')
            analysis_id = f"{stock_symbol}_{timestamp.strftime('%Y%m%d_%H%M%S')}"

            # å¤„ç†reportså­—æ®µ - ä»stateä¸­æå–æ‰€æœ‰åˆ†ææŠ¥å‘Š
            reports = {}
            if 'state' in result:
                try:
                    state = result['state']

                    # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„æŠ¥å‘Šå­—æ®µ
                    report_fields = [
                        'market_report',
                        'sentiment_report',
                        'news_report',
                        'fundamentals_report',
                        'investment_plan',
                        'trader_investment_plan',
                        'final_trade_decision'
                    ]

                    # ä»stateä¸­æå–æŠ¥å‘Šå†…å®¹
                    for field in report_fields:
                        if hasattr(state, field):
                            value = getattr(state, field, "")
                        elif isinstance(state, dict) and field in state:
                            value = state[field]
                        else:
                            value = ""

                        if isinstance(value, str) and len(value.strip()) > 10:  # åªä¿å­˜æœ‰å®é™…å†…å®¹çš„æŠ¥å‘Š
                            reports[field] = value.strip()

                    # å¤„ç†å¤æ‚çš„è¾©è®ºçŠ¶æ€æŠ¥å‘Š
                    if hasattr(state, 'investment_debate_state') or (isinstance(state, dict) and 'investment_debate_state' in state):
                        debate_state = getattr(state, 'investment_debate_state', None) if hasattr(state, 'investment_debate_state') else state.get('investment_debate_state')
                        if debate_state:
                            if hasattr(debate_state, 'judge_decision'):
                                decision_content = getattr(debate_state, 'judge_decision', "")
                            elif isinstance(debate_state, dict) and 'judge_decision' in debate_state:
                                decision_content = debate_state['judge_decision']
                            else:
                                decision_content = str(debate_state)

                            if decision_content and len(decision_content.strip()) > 10:
                                reports['research_team_decision'] = decision_content.strip()

                    if hasattr(state, 'risk_debate_state') or (isinstance(state, dict) and 'risk_debate_state' in state):
                        risk_state = getattr(state, 'risk_debate_state', None) if hasattr(state, 'risk_debate_state') else state.get('risk_debate_state')
                        if risk_state:
                            if hasattr(risk_state, 'judge_decision'):
                                risk_decision = getattr(risk_state, 'judge_decision', "")
                            elif isinstance(risk_state, dict) and 'judge_decision' in risk_state:
                                risk_decision = risk_state['judge_decision']
                            else:
                                risk_decision = str(risk_state)

                            if risk_decision and len(risk_decision.strip()) > 10:
                                reports['risk_management_decision'] = risk_decision.strip()

                    logger.info(f"ğŸ“Š ä»stateä¸­æå–åˆ° {len(reports)} ä¸ªæŠ¥å‘Š: {list(reports.keys())}")

                except Exception as e:
                    logger.warning(f"âš ï¸ å¤„ç†stateä¸­çš„reportsæ—¶å‡ºé”™: {e}")
                    # é™çº§åˆ°ä»detailed_analysisæå–
                    if 'detailed_analysis' in result:
                        try:
                            detailed_analysis = result['detailed_analysis']
                            if isinstance(detailed_analysis, dict):
                                for key, value in detailed_analysis.items():
                                    if isinstance(value, str) and len(value) > 50:
                                        reports[key] = value
                                logger.info(f"ğŸ“Š é™çº§ï¼šä»detailed_analysisä¸­æå–åˆ° {len(reports)} ä¸ªæŠ¥å‘Š")
                        except Exception as fallback_error:
                            logger.warning(f"âš ï¸ é™çº§æå–ä¹Ÿå¤±è´¥: {fallback_error}")

            # æ„å»ºæ–‡æ¡£ï¼ˆä¸webç›®å½•çš„MongoDBReportManagerä¿æŒä¸€è‡´ï¼‰
            document = {
                "analysis_id": analysis_id,
                "stock_symbol": stock_symbol,
                "analysis_date": timestamp.strftime('%Y-%m-%d'),
                "timestamp": timestamp,
                "status": "completed",
                "source": "api",

                # åˆ†æç»“æœæ‘˜è¦
                "summary": result.get("summary", ""),
                "analysts": result.get("analysts", []),
                "research_depth": result.get("research_depth", 1),

                # æŠ¥å‘Šå†…å®¹
                "reports": reports,

                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ æ ¼å¼åŒ–åçš„decisionå­—æ®µï¼
                "decision": result.get("decision", {}),

                # å…ƒæ•°æ®
                "created_at": timestamp,
                "updated_at": timestamp,

                # APIç‰¹æœ‰å­—æ®µ
                "task_id": task_id,
                "recommendation": result.get("recommendation", ""),
                "confidence_score": result.get("confidence_score", 0.0),
                "risk_level": result.get("risk_level", "ä¸­ç­‰"),
                "key_points": result.get("key_points", []),
                "execution_time": result.get("execution_time", 0),
                "tokens_used": result.get("tokens_used", 0)
            }

            # ä¿å­˜åˆ°analysis_reportsé›†åˆï¼ˆä¸webç›®å½•ä¿æŒä¸€è‡´ï¼‰
            result_insert = await db.analysis_reports.insert_one(document)

            if result_insert.inserted_id:
                logger.info(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°MongoDB analysis_reports: {analysis_id}")

                # åŒæ—¶æ›´æ–°analysis_tasksé›†åˆä¸­çš„resultå­—æ®µï¼Œä¿æŒAPIå…¼å®¹æ€§
                await db.analysis_tasks.update_one(
                    {"task_id": task_id},
                    {"$set": {"result": {
                        "analysis_id": analysis_id,
                        "stock_symbol": stock_symbol,
                        "stock_code": result.get('stock_code', stock_symbol),
                        "analysis_date": result.get('analysis_date'),
                        "summary": result.get("summary", ""),
                        "recommendation": result.get("recommendation", ""),
                        "confidence_score": result.get("confidence_score", 0.0),
                        "risk_level": result.get("risk_level", "ä¸­ç­‰"),
                        "key_points": result.get("key_points", []),
                        "detailed_analysis": result.get("detailed_analysis", {}),
                        "execution_time": result.get("execution_time", 0),
                        "tokens_used": result.get("tokens_used", 0),
                        "reports": reports,  # åŒ…å«æå–çš„æŠ¥å‘Šå†…å®¹
                        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ æ ¼å¼åŒ–åçš„decisionå­—æ®µï¼
                        "decision": result.get("decision", {})
                    }}}
                )
                logger.info(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜ (webé£æ ¼): {task_id}")
            else:
                logger.error("âŒ MongoDBæ’å…¥å¤±è´¥")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {task_id} - {e}")
            # é™çº§åˆ°ç®€å•ä¿å­˜
            try:
                simple_result = {
                    'task_id': task_id,
                    'success': result.get('success', True),
                    'error': str(e),
                    'completed_at': datetime.utcnow().isoformat()
                }
                await db.analysis_tasks.update_one(
                    {"task_id": task_id},
                    {"$set": {"result": simple_result}}
                )
                logger.info(f"ğŸ’¾ ä½¿ç”¨ç®€åŒ–ç»“æœä¿å­˜: {task_id}")
            except Exception as fallback_error:
                logger.error(f"âŒ ç®€åŒ–ä¿å­˜ä¹Ÿå¤±è´¥: {task_id} - {fallback_error}")

    async def _save_analysis_results_complete(self, task_id: str, result: Dict[str, Any]):
        """å®Œæ•´çš„åˆ†æç»“æœä¿å­˜ - å®Œå…¨é‡‡ç”¨webç›®å½•çš„åŒé‡ä¿å­˜æ–¹å¼"""
        try:
            # è°ƒè¯•ï¼šæ‰“å°resultä¸­çš„æ‰€æœ‰é”®
            logger.info(f"ğŸ” [è°ƒè¯•] resultä¸­çš„æ‰€æœ‰é”®: {list(result.keys())}")
            logger.info(f"ğŸ” [è°ƒè¯•] stock_code: {result.get('stock_code', 'NOT_FOUND')}")
            logger.info(f"ğŸ” [è°ƒè¯•] stock_symbol: {result.get('stock_symbol', 'NOT_FOUND')}")

            # ä¼˜å…ˆä½¿ç”¨stock_symbolï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨stock_code
            stock_symbol = result.get('stock_symbol') or result.get('stock_code', 'UNKNOWN')
            logger.info(f"ğŸ’¾ å¼€å§‹å®Œæ•´ä¿å­˜åˆ†æç»“æœ: {stock_symbol}")

            # 1. ä¿å­˜åˆ†æ¨¡å—æŠ¥å‘Šåˆ°æœ¬åœ°ç›®å½•
            logger.info(f"ğŸ“ [æœ¬åœ°ä¿å­˜] å¼€å§‹ä¿å­˜åˆ†æ¨¡å—æŠ¥å‘Šåˆ°æœ¬åœ°ç›®å½•")
            local_files = await self._save_modular_reports_to_data_dir(result, stock_symbol)
            if local_files:
                logger.info(f"âœ… [æœ¬åœ°ä¿å­˜] å·²ä¿å­˜ {len(local_files)} ä¸ªæœ¬åœ°æŠ¥å‘Šæ–‡ä»¶")
                for module, path in local_files.items():
                    logger.info(f"  - {module}: {path}")
            else:
                logger.warning(f"âš ï¸ [æœ¬åœ°ä¿å­˜] æœ¬åœ°æŠ¥å‘Šæ–‡ä»¶ä¿å­˜å¤±è´¥")

            # 2. ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ•°æ®åº“
            logger.info(f"ğŸ—„ï¸ [æ•°æ®åº“ä¿å­˜] å¼€å§‹ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ•°æ®åº“")
            await self._save_analysis_result_web_style(task_id, result)
            logger.info(f"âœ… [æ•°æ®åº“ä¿å­˜] åˆ†ææŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")

            # 3. è®°å½•ä¿å­˜ç»“æœ
            if local_files:
                logger.info(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°æ•°æ®åº“å’Œæœ¬åœ°æ–‡ä»¶")
            else:
                logger.warning(f"âš ï¸ æ•°æ®åº“ä¿å­˜æˆåŠŸï¼Œä½†æœ¬åœ°æ–‡ä»¶ä¿å­˜å¤±è´¥")

        except Exception as save_error:
            logger.error(f"âŒ [å®Œæ•´ä¿å­˜] ä¿å­˜åˆ†ææŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {str(save_error)}")
            # é™çº§åˆ°ä»…æ•°æ®åº“ä¿å­˜
            try:
                await self._save_analysis_result_web_style(task_id, result)
                logger.info(f"ğŸ’¾ é™çº§ä¿å­˜æˆåŠŸ (ä»…æ•°æ®åº“): {task_id}")
            except Exception as fallback_error:
                logger.error(f"âŒ é™çº§ä¿å­˜ä¹Ÿå¤±è´¥: {task_id} - {fallback_error}")

    async def _save_modular_reports_to_data_dir(self, result: Dict[str, Any], stock_symbol: str) -> Dict[str, str]:
        """ä¿å­˜åˆ†æ¨¡å—æŠ¥å‘Šåˆ°dataç›®å½• - å®Œå…¨é‡‡ç”¨webç›®å½•çš„æ–‡ä»¶ç»“æ„"""
        try:
            import os
            from pathlib import Path
            from datetime import datetime
            import json

            # è·å–é¡¹ç›®æ ¹ç›®å½•
            project_root = Path(__file__).parent.parent.parent

            # ç¡®å®šresultsç›®å½•è·¯å¾„ - ä¸webç›®å½•ä¿æŒä¸€è‡´
            results_dir_env = os.getenv("TRADINGAGENTS_RESULTS_DIR")
            if results_dir_env:
                if not os.path.isabs(results_dir_env):
                    results_dir = project_root / results_dir_env
                else:
                    results_dir = Path(results_dir_env)
            else:
                # é»˜è®¤ä½¿ç”¨dataç›®å½•è€Œä¸æ˜¯resultsç›®å½•
                results_dir = project_root / "data" / "analysis_results"

            # åˆ›å»ºè‚¡ç¥¨ä¸“ç”¨ç›®å½• - å®Œå…¨æŒ‰ç…§webç›®å½•çš„ç»“æ„
            analysis_date_raw = result.get('analysis_date', datetime.now())

            # ç¡®ä¿ analysis_date æ˜¯å­—ç¬¦ä¸²æ ¼å¼
            if isinstance(analysis_date_raw, datetime):
                analysis_date_str = analysis_date_raw.strftime('%Y-%m-%d')
            elif isinstance(analysis_date_raw, str):
                # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œæ£€æŸ¥æ ¼å¼
                try:
                    # å°è¯•è§£ææ—¥æœŸå­—ç¬¦ä¸²ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                    parsed_date = datetime.strptime(analysis_date_raw, '%Y-%m-%d')
                    analysis_date_str = analysis_date_raw
                except ValueError:
                    # å¦‚æœæ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
                    analysis_date_str = datetime.now().strftime('%Y-%m-%d')
            else:
                # å…¶ä»–ç±»å‹ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
                analysis_date_str = datetime.now().strftime('%Y-%m-%d')

            stock_dir = results_dir / stock_symbol / analysis_date_str
            reports_dir = stock_dir / "reports"
            reports_dir.mkdir(parents=True, exist_ok=True)

            # åˆ›å»ºmessage_tool.logæ–‡ä»¶ - ä¸webç›®å½•ä¿æŒä¸€è‡´
            log_file = stock_dir / "message_tool.log"
            log_file.touch(exist_ok=True)

            logger.info(f"ğŸ“ åˆ›å»ºåˆ†æç»“æœç›®å½•: {reports_dir}")
            logger.info(f"ğŸ” [è°ƒè¯•] analysis_date_raw ç±»å‹: {type(analysis_date_raw)}, å€¼: {analysis_date_raw}")
            logger.info(f"ğŸ” [è°ƒè¯•] analysis_date_str: {analysis_date_str}")
            logger.info(f"ğŸ” [è°ƒè¯•] å®Œæ•´è·¯å¾„: {os.path.normpath(str(reports_dir))}")

            state = result.get('state', {})
            saved_files = {}

            # å®šä¹‰æŠ¥å‘Šæ¨¡å—æ˜ å°„ - å®Œå…¨æŒ‰ç…§webç›®å½•çš„å®šä¹‰
            report_modules = {
                'market_report': {
                    'filename': 'market_report.md',
                    'title': f'{stock_symbol} è‚¡ç¥¨æŠ€æœ¯åˆ†ææŠ¥å‘Š',
                    'state_key': 'market_report'
                },
                'sentiment_report': {
                    'filename': 'sentiment_report.md',
                    'title': f'{stock_symbol} å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š',
                    'state_key': 'sentiment_report'
                },
                'news_report': {
                    'filename': 'news_report.md',
                    'title': f'{stock_symbol} æ–°é—»äº‹ä»¶åˆ†ææŠ¥å‘Š',
                    'state_key': 'news_report'
                },
                'fundamentals_report': {
                    'filename': 'fundamentals_report.md',
                    'title': f'{stock_symbol} åŸºæœ¬é¢åˆ†ææŠ¥å‘Š',
                    'state_key': 'fundamentals_report'
                },
                'investment_plan': {
                    'filename': 'investment_plan.md',
                    'title': f'{stock_symbol} æŠ•èµ„å†³ç­–æŠ¥å‘Š',
                    'state_key': 'investment_plan'
                },
                'trader_investment_plan': {
                    'filename': 'trader_investment_plan.md',
                    'title': f'{stock_symbol} äº¤æ˜“è®¡åˆ’æŠ¥å‘Š',
                    'state_key': 'trader_investment_plan'
                },
                'final_trade_decision': {
                    'filename': 'final_trade_decision.md',
                    'title': f'{stock_symbol} æœ€ç»ˆæŠ•èµ„å†³ç­–',
                    'state_key': 'final_trade_decision'
                },
                'investment_debate_state': {
                    'filename': 'research_team_decision.md',
                    'title': f'{stock_symbol} ç ”ç©¶å›¢é˜Ÿå†³ç­–æŠ¥å‘Š',
                    'state_key': 'investment_debate_state'
                },
                'risk_debate_state': {
                    'filename': 'risk_management_decision.md',
                    'title': f'{stock_symbol} é£é™©ç®¡ç†å›¢é˜Ÿå†³ç­–æŠ¥å‘Š',
                    'state_key': 'risk_debate_state'
                }
            }

            # ä¿å­˜å„æ¨¡å—æŠ¥å‘Š - å®Œå…¨æŒ‰ç…§webç›®å½•çš„æ–¹å¼
            for module_key, module_info in report_modules.items():
                try:
                    state_key = module_info['state_key']
                    if state_key in state:
                        # æå–æ¨¡å—å†…å®¹
                        module_content = state[state_key]
                        if isinstance(module_content, str):
                            report_content = module_content
                        else:
                            report_content = str(module_content)

                        # ä¿å­˜åˆ°æ–‡ä»¶ - ä½¿ç”¨webç›®å½•çš„æ–‡ä»¶å
                        file_path = reports_dir / module_info['filename']
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(report_content)

                        saved_files[module_key] = str(file_path)
                        logger.info(f"âœ… ä¿å­˜æ¨¡å—æŠ¥å‘Š: {file_path}")

                except Exception as e:
                    logger.warning(f"âš ï¸ ä¿å­˜æ¨¡å— {module_key} å¤±è´¥: {e}")

            # ä¿å­˜æœ€ç»ˆå†³ç­–æŠ¥å‘Š - å®Œå…¨æŒ‰ç…§webç›®å½•çš„æ–¹å¼
            decision = result.get('decision', {})
            if decision:
                decision_content = f"# {stock_symbol} æœ€ç»ˆæŠ•èµ„å†³ç­–\n\n"

                if isinstance(decision, dict):
                    decision_content += f"## æŠ•èµ„å»ºè®®\n\n"
                    decision_content += f"**è¡ŒåŠ¨**: {decision.get('action', 'N/A')}\n\n"
                    decision_content += f"**ç½®ä¿¡åº¦**: {decision.get('confidence', 0):.1%}\n\n"
                    decision_content += f"**é£é™©è¯„åˆ†**: {decision.get('risk_score', 0):.1%}\n\n"
                    decision_content += f"**ç›®æ ‡ä»·ä½**: {decision.get('target_price', 'N/A')}\n\n"
                    decision_content += f"## åˆ†ææ¨ç†\n\n{decision.get('reasoning', 'æš‚æ— åˆ†ææ¨ç†')}\n\n"
                else:
                    decision_content += f"{str(decision)}\n\n"

                decision_file = reports_dir / "final_trade_decision.md"
                with open(decision_file, 'w', encoding='utf-8') as f:
                    f.write(decision_content)

                saved_files['final_trade_decision'] = str(decision_file)
                logger.info(f"âœ… ä¿å­˜æœ€ç»ˆå†³ç­–: {decision_file}")

            # ä¿å­˜åˆ†æå…ƒæ•°æ®æ–‡ä»¶ - å®Œå…¨æŒ‰ç…§webç›®å½•çš„æ–¹å¼
            metadata = {
                'stock_symbol': stock_symbol,
                'analysis_date': analysis_date_str,
                'timestamp': datetime.now().isoformat(),
                'research_depth': result.get('research_depth', 1),
                'analysts': result.get('analysts', []),
                'status': 'completed',
                'reports_count': len(saved_files),
                'report_types': list(saved_files.keys())
            }

            metadata_file = reports_dir.parent / "analysis_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… ä¿å­˜åˆ†æå…ƒæ•°æ®: {metadata_file}")
            logger.info(f"âœ… åˆ†æ¨¡å—æŠ¥å‘Šä¿å­˜å®Œæˆï¼Œå…±ä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶")
            logger.info(f"ğŸ“ ä¿å­˜ç›®å½•: {os.path.normpath(str(reports_dir))}")

            return saved_files

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æ¨¡å—æŠ¥å‘Šå¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {}
    
# é‡å¤çš„ get_task_status æ–¹æ³•å·²åˆ é™¤ï¼Œä½¿ç”¨ç¬¬469è¡Œçš„å†…å­˜ç‰ˆæœ¬


# å…¨å±€æœåŠ¡å®ä¾‹
_analysis_service = None

def get_simple_analysis_service() -> SimpleAnalysisService:
    """è·å–åˆ†ææœåŠ¡å®ä¾‹"""
    global _analysis_service
    if _analysis_service is None:
        logger.info("ğŸ”§ [å•ä¾‹] åˆ›å»ºæ–°çš„ SimpleAnalysisService å®ä¾‹")
        _analysis_service = SimpleAnalysisService()
    else:
        logger.info(f"ğŸ”§ [å•ä¾‹] è¿”å›ç°æœ‰çš„ SimpleAnalysisService å®ä¾‹: {id(_analysis_service)}")
    return _analysis_service
