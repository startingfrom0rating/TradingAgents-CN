"""
Tushareæ•°æ®åŒæ­¥æœåŠ¡
è´Ÿè´£å°†Tushareæ•°æ®åŒæ­¥åˆ°MongoDBæ ‡å‡†åŒ–é›†åˆ
"""
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import logging

from tradingagents.dataflows.providers.tushare_provider import TushareProvider
from app.services.stock_data_service import get_stock_data_service
from app.core.database import get_mongo_db
from app.core.config import settings

logger = logging.getLogger(__name__)


class TushareSyncService:
    """
    Tushareæ•°æ®åŒæ­¥æœåŠ¡
    è´Ÿè´£å°†Tushareæ•°æ®åŒæ­¥åˆ°MongoDBæ ‡å‡†åŒ–é›†åˆ
    """
    
    def __init__(self):
        self.provider = TushareProvider()
        self.stock_service = get_stock_data_service()
        self.db = get_mongo_db()
        self.settings = settings
        
        # åŒæ­¥é…ç½®
        self.batch_size = 100  # æ‰¹é‡å¤„ç†å¤§å°
        self.rate_limit_delay = 0.1  # APIè°ƒç”¨é—´éš”(ç§’)
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    
    async def initialize(self):
        """åˆå§‹åŒ–åŒæ­¥æœåŠ¡"""
        success = await self.provider.connect()
        if not success:
            raise RuntimeError("âŒ Tushareè¿æ¥å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨åŒæ­¥æœåŠ¡")
        
        logger.info("âœ… TushareåŒæ­¥æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    # ==================== åŸºç¡€ä¿¡æ¯åŒæ­¥ ====================
    
    async def sync_stock_basic_info(self, force_update: bool = False) -> Dict[str, Any]:
        """
        åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        
        Args:
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°æ‰€æœ‰æ•°æ®
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        
        stats = {
            "total_processed": 0,
            "success_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "start_time": datetime.utcnow(),
            "errors": []
        }
        
        try:
            # 1. ä»Tushareè·å–è‚¡ç¥¨åˆ—è¡¨
            stock_list = await self.provider.get_stock_list(market="CN")
            if not stock_list:
                logger.error("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return stats
            
            stats["total_processed"] = len(stock_list)
            logger.info(f"ğŸ“Š è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨ä¿¡æ¯")
            
            # 2. æ‰¹é‡å¤„ç†
            for i in range(0, len(stock_list), self.batch_size):
                batch = stock_list[i:i + self.batch_size]
                batch_stats = await self._process_basic_info_batch(batch, force_update)
                
                # æ›´æ–°ç»Ÿè®¡
                stats["success_count"] += batch_stats["success_count"]
                stats["error_count"] += batch_stats["error_count"]
                stats["skipped_count"] += batch_stats["skipped_count"]
                stats["errors"].extend(batch_stats["errors"])
                
                # è¿›åº¦æ—¥å¿—
                progress = min(i + self.batch_size, len(stock_list))
                logger.info(f"ğŸ“ˆ åŸºç¡€ä¿¡æ¯åŒæ­¥è¿›åº¦: {progress}/{len(stock_list)} "
                           f"(æˆåŠŸ: {stats['success_count']}, é”™è¯¯: {stats['error_count']})")
                
                # APIé™æµ
                if i + self.batch_size < len(stock_list):
                    await asyncio.sleep(self.rate_limit_delay)
            
            # 3. å®Œæˆç»Ÿè®¡
            stats["end_time"] = datetime.utcnow()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()
            
            logger.info(f"âœ… è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åŒæ­¥å®Œæˆ: "
                       f"æ€»è®¡ {stats['total_processed']} åª, "
                       f"æˆåŠŸ {stats['success_count']} åª, "
                       f"é”™è¯¯ {stats['error_count']} åª, "
                       f"è·³è¿‡ {stats['skipped_count']} åª, "
                       f"è€—æ—¶ {stats['duration']:.2f} ç§’")
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åŒæ­¥å¤±è´¥: {e}")
            stats["errors"].append({"error": str(e), "context": "sync_stock_basic_info"})
            return stats
    
    async def _process_basic_info_batch(self, batch: List[Dict[str, Any]], force_update: bool) -> Dict[str, Any]:
        """å¤„ç†åŸºç¡€ä¿¡æ¯æ‰¹æ¬¡"""
        batch_stats = {
            "success_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "errors": []
        }
        
        for stock_info in batch:
            try:
                code = stock_info["code"]
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                if not force_update:
                    existing = await self.stock_service.get_stock_basic_info(code)
                    if existing and self._is_data_fresh(existing.get("updated_at"), hours=24):
                        batch_stats["skipped_count"] += 1
                        continue
                
                # æ›´æ–°åˆ°æ•°æ®åº“
                success = await self.stock_service.update_stock_basic_info(code, stock_info)
                if success:
                    batch_stats["success_count"] += 1
                else:
                    batch_stats["error_count"] += 1
                    batch_stats["errors"].append({
                        "code": code,
                        "error": "æ•°æ®åº“æ›´æ–°å¤±è´¥",
                        "context": "update_stock_basic_info"
                    })
                
            except Exception as e:
                batch_stats["error_count"] += 1
                batch_stats["errors"].append({
                    "code": stock_info.get("code", "unknown"),
                    "error": str(e),
                    "context": "_process_basic_info_batch"
                })
        
        return batch_stats
    
    # ==================== å®æ—¶è¡Œæƒ…åŒæ­¥ ====================
    
    async def sync_realtime_quotes(self, symbols: List[str] = None) -> Dict[str, Any]:
        """
        åŒæ­¥å®æ—¶è¡Œæƒ…æ•°æ®
        
        Args:
            symbols: æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºç©ºåˆ™åŒæ­¥æ‰€æœ‰è‚¡ç¥¨
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥å®æ—¶è¡Œæƒ…...")
        
        stats = {
            "total_processed": 0,
            "success_count": 0,
            "error_count": 0,
            "start_time": datetime.utcnow(),
            "errors": []
        }
        
        try:
            # 1. è·å–éœ€è¦åŒæ­¥çš„è‚¡ç¥¨åˆ—è¡¨
            if symbols is None:
                cursor = self.db.stock_basic_info.find(
                    {"market_info.market": "CN"}, 
                    {"code": 1}
                )
                symbols = [doc["code"] async for doc in cursor]
            
            stats["total_processed"] = len(symbols)
            logger.info(f"ğŸ“Š éœ€è¦åŒæ­¥ {len(symbols)} åªè‚¡ç¥¨è¡Œæƒ…")
            
            # 2. æ‰¹é‡å¤„ç†
            for i in range(0, len(symbols), self.batch_size):
                batch = symbols[i:i + self.batch_size]
                batch_stats = await self._process_quotes_batch(batch)
                
                # æ›´æ–°ç»Ÿè®¡
                stats["success_count"] += batch_stats["success_count"]
                stats["error_count"] += batch_stats["error_count"]
                stats["errors"].extend(batch_stats["errors"])
                
                # è¿›åº¦æ—¥å¿—
                progress = min(i + self.batch_size, len(symbols))
                logger.info(f"ğŸ“ˆ è¡Œæƒ…åŒæ­¥è¿›åº¦: {progress}/{len(symbols)} "
                           f"(æˆåŠŸ: {stats['success_count']}, é”™è¯¯: {stats['error_count']})")
                
                # APIé™æµ
                if i + self.batch_size < len(symbols):
                    await asyncio.sleep(self.rate_limit_delay)
            
            # 3. å®Œæˆç»Ÿè®¡
            stats["end_time"] = datetime.utcnow()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()
            
            logger.info(f"âœ… å®æ—¶è¡Œæƒ…åŒæ­¥å®Œæˆ: "
                       f"æ€»è®¡ {stats['total_processed']} åª, "
                       f"æˆåŠŸ {stats['success_count']} åª, "
                       f"é”™è¯¯ {stats['error_count']} åª, "
                       f"è€—æ—¶ {stats['duration']:.2f} ç§’")
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ å®æ—¶è¡Œæƒ…åŒæ­¥å¤±è´¥: {e}")
            stats["errors"].append({"error": str(e), "context": "sync_realtime_quotes"})
            return stats
    
    async def _process_quotes_batch(self, batch: List[str]) -> Dict[str, Any]:
        """å¤„ç†è¡Œæƒ…æ‰¹æ¬¡"""
        batch_stats = {
            "success_count": 0,
            "error_count": 0,
            "errors": []
        }
        
        # å¹¶å‘è·å–è¡Œæƒ…æ•°æ®
        tasks = []
        for symbol in batch:
            task = self._get_and_save_quotes(symbol)
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                batch_stats["error_count"] += 1
                batch_stats["errors"].append({
                    "code": batch[i],
                    "error": str(result),
                    "context": "_process_quotes_batch"
                })
            elif result:
                batch_stats["success_count"] += 1
            else:
                batch_stats["error_count"] += 1
                batch_stats["errors"].append({
                    "code": batch[i],
                    "error": "è·å–è¡Œæƒ…æ•°æ®å¤±è´¥",
                    "context": "_process_quotes_batch"
                })
        
        return batch_stats
    
    async def _get_and_save_quotes(self, symbol: str) -> bool:
        """è·å–å¹¶ä¿å­˜å•ä¸ªè‚¡ç¥¨è¡Œæƒ…"""
        try:
            quotes = await self.provider.get_stock_quotes(symbol)
            if quotes:
                return await self.stock_service.update_market_quotes(symbol, quotes)
            return False
        except Exception as e:
            logger.error(f"âŒ è·å– {symbol} è¡Œæƒ…å¤±è´¥: {e}")
            return False

    # ==================== å†å²æ•°æ®åŒæ­¥ ====================

    async def sync_historical_data(
        self,
        symbols: List[str] = None,
        start_date: str = None,
        end_date: str = None,
        incremental: bool = True
    ) -> Dict[str, Any]:
        """
        åŒæ­¥å†å²æ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            incremental: æ˜¯å¦å¢é‡åŒæ­¥

        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥å†å²æ•°æ®...")

        stats = {
            "total_processed": 0,
            "success_count": 0,
            "error_count": 0,
            "total_records": 0,
            "start_time": datetime.utcnow(),
            "errors": []
        }

        try:
            # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
            if symbols is None:
                cursor = self.db.stock_basic_info.find(
                    {"market_info.market": "CN"},
                    {"code": 1}
                )
                symbols = [doc["code"] async for doc in cursor]

            stats["total_processed"] = len(symbols)

            # 2. ç¡®å®šæ—¥æœŸèŒƒå›´
            if not start_date:
                if incremental:
                    # å¢é‡åŒæ­¥ï¼šä»æœ€åæ›´æ–°æ—¥æœŸå¼€å§‹
                    start_date = await self._get_last_sync_date()
                else:
                    # å…¨é‡åŒæ­¥ï¼šä»ä¸€å¹´å‰å¼€å§‹
                    start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')

            if not end_date:
                end_date = datetime.now().strftime('%Y-%m-%d')

            logger.info(f"ğŸ“Š å†å²æ•°æ®åŒæ­¥èŒƒå›´: {start_date} åˆ° {end_date}, è‚¡ç¥¨æ•°é‡: {len(symbols)}")

            # 3. æ‰¹é‡å¤„ç†
            for i, symbol in enumerate(symbols):
                try:
                    # è·å–å†å²æ•°æ®
                    df = await self.provider.get_historical_data(symbol, start_date, end_date)

                    if df is not None and not df.empty:
                        # ä¿å­˜åˆ°æ•°æ®åº“
                        records_saved = await self._save_historical_data(symbol, df)
                        stats["success_count"] += 1
                        stats["total_records"] += records_saved

                        logger.debug(f"âœ… {symbol}: ä¿å­˜ {records_saved} æ¡å†å²è®°å½•")
                    else:
                        logger.warning(f"âš ï¸ {symbol}: æ— å†å²æ•°æ®")

                    # è¿›åº¦æ—¥å¿—
                    if (i + 1) % 50 == 0:
                        logger.info(f"ğŸ“ˆ å†å²æ•°æ®åŒæ­¥è¿›åº¦: {i + 1}/{len(symbols)} "
                                   f"(æˆåŠŸ: {stats['success_count']}, è®°å½•: {stats['total_records']})")

                    # APIé™æµ
                    await asyncio.sleep(self.rate_limit_delay)

                except Exception as e:
                    stats["error_count"] += 1
                    stats["errors"].append({
                        "code": symbol,
                        "error": str(e),
                        "context": "sync_historical_data"
                    })
                    logger.error(f"âŒ {symbol} å†å²æ•°æ®åŒæ­¥å¤±è´¥: {e}")

            # 4. å®Œæˆç»Ÿè®¡
            stats["end_time"] = datetime.utcnow()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()

            logger.info(f"âœ… å†å²æ•°æ®åŒæ­¥å®Œæˆ: "
                       f"è‚¡ç¥¨ {stats['success_count']}/{stats['total_processed']}, "
                       f"è®°å½• {stats['total_records']} æ¡, "
                       f"é”™è¯¯ {stats['error_count']} ä¸ª, "
                       f"è€—æ—¶ {stats['duration']:.2f} ç§’")

            return stats

        except Exception as e:
            logger.error(f"âŒ å†å²æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            stats["errors"].append({"error": str(e), "context": "sync_historical_data"})
            return stats

    async def _save_historical_data(self, symbol: str, df) -> int:
        """ä¿å­˜å†å²æ•°æ®åˆ°æ•°æ®åº“"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ•°æ®åº“è®¾è®¡æ¥å®ç°
        # å¯èƒ½éœ€è¦åˆ›å»ºæ–°çš„å†å²æ•°æ®é›†åˆ
        # æš‚æ—¶è¿”å›æ•°æ®æ¡æ•°
        return len(df)

    async def _get_last_sync_date(self) -> str:
        """è·å–æœ€ååŒæ­¥æ—¥æœŸ"""
        # æŸ¥è¯¢æœ€æ–°çš„å†å²æ•°æ®æ—¥æœŸ
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ•°æ®åº“è®¾è®¡æ¥å®ç°
        return (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')

    # ==================== è´¢åŠ¡æ•°æ®åŒæ­¥ ====================

    async def sync_financial_data(self, symbols: List[str] = None) -> Dict[str, Any]:
        """åŒæ­¥è´¢åŠ¡æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥è´¢åŠ¡æ•°æ®...")

        stats = {
            "total_processed": 0,
            "success_count": 0,
            "error_count": 0,
            "start_time": datetime.utcnow(),
            "errors": []
        }

        try:
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            if symbols is None:
                cursor = self.db.stock_basic_info.find(
                    {"market_info.market": "CN"},
                    {"code": 1}
                )
                symbols = [doc["code"] async for doc in cursor]

            stats["total_processed"] = len(symbols)
            logger.info(f"ğŸ“Š éœ€è¦åŒæ­¥ {len(symbols)} åªè‚¡ç¥¨è´¢åŠ¡æ•°æ®")

            # æ‰¹é‡å¤„ç†
            for i, symbol in enumerate(symbols):
                try:
                    financial_data = await self.provider.get_financial_data(symbol)

                    if financial_data:
                        # ä¿å­˜è´¢åŠ¡æ•°æ®
                        success = await self._save_financial_data(symbol, financial_data)
                        if success:
                            stats["success_count"] += 1
                        else:
                            stats["error_count"] += 1
                    else:
                        logger.warning(f"âš ï¸ {symbol}: æ— è´¢åŠ¡æ•°æ®")

                    # è¿›åº¦æ—¥å¿—
                    if (i + 1) % 20 == 0:
                        logger.info(f"ğŸ“ˆ è´¢åŠ¡æ•°æ®åŒæ­¥è¿›åº¦: {i + 1}/{len(symbols)} "
                                   f"(æˆåŠŸ: {stats['success_count']}, é”™è¯¯: {stats['error_count']})")

                    # APIé™æµ (è´¢åŠ¡æ•°æ®è°ƒç”¨é¢‘ç‡æ›´ä¸¥æ ¼)
                    await asyncio.sleep(self.rate_limit_delay * 2)

                except Exception as e:
                    stats["error_count"] += 1
                    stats["errors"].append({
                        "code": symbol,
                        "error": str(e),
                        "context": "sync_financial_data"
                    })
                    logger.error(f"âŒ {symbol} è´¢åŠ¡æ•°æ®åŒæ­¥å¤±è´¥: {e}")

            # å®Œæˆç»Ÿè®¡
            stats["end_time"] = datetime.utcnow()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()

            logger.info(f"âœ… è´¢åŠ¡æ•°æ®åŒæ­¥å®Œæˆ: "
                       f"æˆåŠŸ {stats['success_count']}/{stats['total_processed']}, "
                       f"é”™è¯¯ {stats['error_count']} ä¸ª, "
                       f"è€—æ—¶ {stats['duration']:.2f} ç§’")

            return stats

        except Exception as e:
            logger.error(f"âŒ è´¢åŠ¡æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            stats["errors"].append({"error": str(e), "context": "sync_financial_data"})
            return stats

    async def _save_financial_data(self, symbol: str, financial_data: Dict[str, Any]) -> bool:
        """ä¿å­˜è´¢åŠ¡æ•°æ®"""
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„è´¢åŠ¡æ•°æ®é›†åˆè®¾è®¡æ¥å®ç°
            # å¯èƒ½éœ€è¦åˆ›å»º stock_financial_data é›†åˆ
            collection = self.db.stock_financial_data

            # æ›´æ–°æˆ–æ’å…¥è´¢åŠ¡æ•°æ®
            filter_query = {
                "symbol": symbol,
                "report_period": financial_data.get("report_period")
            }

            update_data = {
                "$set": {
                    **financial_data,
                    "updated_at": datetime.utcnow()
                }
            }

            result = await collection.update_one(
                filter_query,
                update_data,
                upsert=True
            )

            return result.acknowledged

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ {symbol} è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            return False

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _is_data_fresh(self, updated_at: datetime, hours: int = 24) -> bool:
        """æ£€æŸ¥æ•°æ®æ˜¯å¦æ–°é²œ"""
        if not updated_at:
            return False

        threshold = datetime.utcnow() - timedelta(hours=hours)
        return updated_at > threshold

    async def get_sync_status(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        try:
            # ç»Ÿè®¡å„é›†åˆçš„æ•°æ®é‡
            basic_info_count = await self.db.stock_basic_info.count_documents({})
            quotes_count = await self.db.market_quotes.count_documents({})

            # è·å–æœ€æ–°æ›´æ–°æ—¶é—´
            latest_basic = await self.db.stock_basic_info.find_one(
                {},
                sort=[("updated_at", -1)]
            )
            latest_quotes = await self.db.market_quotes.find_one(
                {},
                sort=[("updated_at", -1)]
            )

            return {
                "provider_connected": self.provider.is_available(),
                "collections": {
                    "stock_basic_info": {
                        "count": basic_info_count,
                        "latest_update": latest_basic.get("updated_at") if latest_basic else None
                    },
                    "market_quotes": {
                        "count": quotes_count,
                        "latest_update": latest_quotes.get("updated_at") if latest_quotes else None
                    }
                },
                "status_time": datetime.utcnow()
            }

        except Exception as e:
            logger.error(f"âŒ è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€åŒæ­¥æœåŠ¡å®ä¾‹
_tushare_sync_service = None

async def get_tushare_sync_service() -> TushareSyncService:
    """è·å–TushareåŒæ­¥æœåŠ¡å®ä¾‹"""
    global _tushare_sync_service
    if _tushare_sync_service is None:
        _tushare_sync_service = TushareSyncService()
        await _tushare_sync_service.initialize()
    return _tushare_sync_service
